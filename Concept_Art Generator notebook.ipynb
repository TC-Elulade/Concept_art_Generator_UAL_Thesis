{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MSc Data Science and AI for Creative Industries Thesis Project** \n",
    "# AI Concept Art Generator\n",
    "\n",
    "This notebook can be used to try out my concept art generator, a stable diffusion model I finetuned using anime characters; with this code, you can create rough images that can inspire character designs for your project. You can simply pull this notebook or copy it into your own notebook or Google Colab space.\n",
    "\n",
    "Carrying out the stable diffusion relies on Huggingface's [Diffusers](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image) git repository. Please note that, for easier use, you may want to have a HuggingFace account in order to use the models and datasets involved.\n",
    "\n",
    "Training was carried out using a P5000 using the Paperspace Gradient platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET UP ENVIRONMENT\n",
    "\n",
    "Please ensure that all appropriate libraries, repositories and scripts are installed to use the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "\n",
    "%pip install torch\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Diffusers git repository\n",
    "\n",
    "!git clone https://github.com/huggingface/diffusers\n",
    "%cd diffusers\n",
    "%pip install .\n",
    "%cd /notebooks/diffusers/examples/text_to_image\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate config default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET UP LOGIN\n",
    "\n",
    "As stated earlier, to have the best experience with the generator, you may want to login with a HuggingFace account (although this migh not be necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log into Huggingface to access models and saving abilities\n",
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING THE MODEL\n",
    "\n",
    "With the model, you can generate one image at a time or multiple at once. When inputting text prompts, please do so in the format of a list of phrases as this would make it easier for the AI to understand. If you would like to have characters of darker skin tones, please add \"dark skin\" and \"tan skin\" into your text prompt.\n",
    "\n",
    "**Please take note of the following**\n",
    "- This is an experimental generator finetuned on a small dataset, there may be issues with the output (especially with darker characters). You are advised to alter the text prompts or re-run the model until you obtain images that are to your liking.\n",
    "\n",
    "- The output is **not** meant to be high res or realistic, the point of this generator is to generate rough sketches that can inspire your character designs (this means that you can draw the designs however way you want, changing colour scheme, skin complexions, gender, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import model_info\n",
    "\n",
    "# LoRA weights ~3 MB\n",
    "model_path = \"Christabelle/sd_anime_concept_generator\"\n",
    "\n",
    "info = model_info(model_path)\n",
    "model_base = info.cardData[\"base_model\"]\n",
    "print(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, UniPCMultistepScheduler\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\n",
    "#pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config) #using this scheduler is faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "pipe.unet.load_attn_procs(model_path)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Code adapted from:\n",
    "# https://www.reddit.com/r/StableDiffusion/comments/wxba44/comment/ilqa7an/?utm_source=share&utm_medium=web2x&context=3\n",
    "pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
    "\n",
    "prompt = \"a man in a hunter outfit, white hair, dark skin, tan skin, red eyes, punk motif\"\n",
    "image = pipe(prompt, negative_prompt=\"monochrome,low res,poorly drawn face, mutated body parts, deformed body features, bad anatomy, worst quality, low quality\",num_inference_steps=250).images[0]\n",
    "image.save(\"magician.png\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: \n",
    "# https://colab.research.google.com/github/LambdaLabsML/lambda-diffusers/blob/main/notebooks/pokemon_demo.ipynb#scrollTo=so1GmFN0q_M4\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autocast\n",
    "\n",
    "prompt = \"a man or woman in a school uniform, moon motif, magician, blue hair, mint hair, holding a staff\"\n",
    "scale = 7.5\n",
    "n_samples = 4\n",
    "\n",
    "pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "  images = pipe(n_samples*[prompt], negative_prompt=n_samples*[\"monochrome,low res,poorly drawn face, mutated body parts, deformed body features, bad anatomy, worst quality, low quality\"],guidance_scale=scale,num_inference_steps=250).images\n",
    "\n",
    "grid = image_grid(images, rows=2, cols=2)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
